\documentclass[11pt]{article}
\usepackage{amssymb,amsmath}

%% enable markdown's stars to bold/italic sections of code -- requires lualatex!
\usepackage{luacode,luatexbase}
\begin{luacode}
   -- Use Lua captures to extract material affected by markdown
   function allstars (line) 
      line = string.gsub( line, "(%*%*%*)(.-)(%*%*%*)", "{\\bfseries\\itshape %2}")
      line = string.gsub( line, "(%*%*)(.-)(%*%*)", "{\\bfseries %2}" )
      line = string.gsub( line, "(%*)(.-)(%*)", "{\\itshape %2}" )
      return line
   end
\end{luacode}

\newcommand\markdownon{%
   \directlua{luatexbase.add_to_callback( "process_input_buffer", allstars, "allstars" )}}
\newcommand\markdownoff{%
   \directlua{luatexbase.remove_from_callback( "process_input_buffer", "allstars" )}}



\usepackage[style=authoryear]{biblatex}
\addbibresource{biblio.bib}

\usepackage{pdflscape}

\usepackage{fontspec}
\defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\setmainfont[]{cantarell}

\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{hyperref}
\urlstyle{same}  % don't use monospace font for urls
\usepackage[margin=4pt]{subcaption}

\usepackage[a4paper,left=2cm,right=2cm,top=1.5cm,bottom=1.5cm]{geometry}
\usepackage{longtable,booktabs}

\usepackage{pgfgantt}
\usepackage{rotating}

\usepackage{tocloft}

\renewcommand{\thesubsubsection}{}

\usepackage{xspace}
\newcommand{\project}{WizUs\xspace}

\newcommand{\task}[2]{\vspace{0.5cm}\noindent\emph{Task T#1}: {\bf #2}\par}

\newcommand{\D}[3]{\emph{Deliverable D#1} (M#2): #3\\}

\newcommand{\TODO}[1]{{\color{red}\textbf{TODO: #1}}}

\newcommand{\severin}[1]{{\color{red}\textbf{Severin: #1}}}
\newcommand{\toseverin}[1]{{\color{red}\textbf{To Severin: #1}}}
\newcommand{\eu}[1]{{\color{teal}\textbf{Guidelines EU ERC: #1}}}
\newcommand{\cellgrey}{\cellcolor[gray]{0.85}}


\title{\project - Part B}

\begin{document}
\markdownon
\maketitle

\subsection*{Title of the proposal}\label{title-of-the-proposal}

\textbf{\project: Socially Intelligent Robots to Support Human-Human Interactions}

\subsection*{Acronym}\label{acronym}

\project

\subsection*{Abstract}\label{abstract}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{B1.a. Extended Synopsis of the scientific proposal}\label{part1}
\eu{(max 5 pages)}

\eu{The Extended Synopsis should give a concise presentation of the scientific
proposal, with particular attention to the ground-breaking nature of the
research project and the feasibility of the outlined scientific approach.
Describe the proposed work in the context of the state of the art of the field.
References to literature should also be included. References do not count
towards the page limits. It is important that this extended synopsis contains
all essential information including the feasibility of the scientific proposal
since the panel will only evaluate Part B1 at step 1.}

\subsection{Long-term vision and targeted breakthrough towards that vision}

\subsubsection{Overview}

In a time where robots are on the verge of becoming pervasive in our daily human
environment, can we ensure 'by design' that robots are to become powerful tools
to foster rich, positive interactions \emph{between the people themselves}, and
build a stronger, more cohesive society? Beyond Human-Computer Interaction (HCI)
and Human-Robot Interaction (HRI), \project is a forward-looking,
ground-breaking project that aims at establishing \textbf{Robot-supported
Human-Human Interactions (r-HHI)} as the next step toward a Responsible AI: the
scientific investigation of how social robots can create, shape and support
strong, sustained, positive \emph{human-human} relationships.

'Socially intelligent' robots require unique, beyond state-of-the-art,
capabilities to \emph{(1)} understand the social interactions (social
situation awareness), \emph{(2)} decide the best course of action for
short-term and longer-term social influence, and \emph{(3)} perform the
appropriate social actions and exert appropriate, responsible social influence.

However, extreme complexity hides behind these seemingly well-delineated steps:
not only the required technology is itself beyond state-of-the-art, but the
interplay between technology, socio-cognitive psychology, privacy and ethics is
only starting to be researched and understood. \project offers a ambitious
vision and a strong, evidenced-based, methodology to significantly advance our
understanding of this \emph{wicked problem} -- a problem whose social complexity
means that it has no determinable stopping point~\cite{tonkinwise2015design}.

The \project project unfolds along three main axes:

Firstly, the basic ambition of \project is to create a conceptual
framework around social robots in the human society, by reframing the widely
accepted, yet sorely unspecific, idea of \emph{human-robot interaction} into the
more specific idea of \emph{robot-supported human-human interactions}: the robot
is considered from the perspective of how it can \emph{support} humans, and in
particular, support stronger, positive interactions between humans.

Secondly, the project addresses the key scientific and technical underpinnings
of the first axis:  the scientific understanding and formalisation of the
\emph{social fabric} in which the robot is embedded, in its full complexity:
spatial characteristics (proxemics; group dynamics, complex, dynamic attentional
mechanisms); psycho-social characteristics (social roles and hierarchies; social
groups; mental modelling; anthropomorphic ascriptions); temporal characteristics
(effects of novelty, dynamics of anthropomorphism and mental ascriptions,
shifting group dynamics). This work will result in the formulation of a
socio-cognitive model of the social environment of the robot and the effective
implementation of the model, including the development of a complete social
assessment pipeline, from social signal perception (like automatic attention
tracking, face recognition, sound localisation, etc.) to higher-level
socio-cognitive constructs, including group dynamics and theory of mind. As
detailled in Section B2, this will rely on hybrid AI techniques, including
symbolic (ontologies and first-order logic), sub-symbolic (neural nets) and
hybrid (conceptors) modelling.

Third, the project will address the question of social behaviour generation.
Indeed, designing behaviours that enable sustained, long-term engagement in a
social human-robot interaction is essentially an open research question. Three
main approaches to social behaviours generation exist today:
\textbf{user-induced}, where the end-user interacts with the robot and ascribes
(knowingly or not) complex behaviours to the machine, while in reality the
robot's behaviours are simple and non-goal oriented (eg generating a noise or
a small movement when being touched). This has been used to great effect in
therapy robots, for instance (eg Paro). \textbf{Off-the-shelf behaviours}, where
the robot relies on a set library of behaviours (that might be individually
relatively complex). The approach can elicit a strong initial social response
from the user, but this social response tends to vanish rapidly once the
'tricks' of the robot have been all discovered and become repetitive.  Besides,
as the robot does not typically maintain a long-term socio-cognitive plan of the
interaction, the behaviours are typically perceived as fun, yet pointless. This is often
observed in toy-like robots (eg Vector, Dot \& Dash). Finally, many social
robots avoid altogether the problem of generating behaviours by simply offering
to the end-user control over \textbf{low-level behaviours} (eg, control of the
joints of the robot). This means that, even when the robot has relatively powerful
social perception capabilities (like recognising people and voice), no real
social behaviours is generated.

None of these three approach is satisfactory, and indeed, no approach to date
has been able to engage human users in long-term, sustained interactions.
\project aims at significantly advancing the state of the art in this regard, by
developing a new data-driven, continuous approach: instead of special events
triggering the replay of a pre-programmed behaviours (as in the current state-of-art), we
will use machine learning (specifically, a combination of Learning from
Demonstration and Interactive Machine Learning) to teach robots to generate
continuous \emph{expressive \& social motions} (including gestures and gazes).

\TODO{discuss Liveliness (Pepper/Nao), Curiosity-based (\cite{kaplan}),
human-in-the-loop (\cite{senft, winkle})}

Critically, the scientific investigation of these three axes (\emph{conceptual
framing of robot-supported human-human interaction}, \emph{online social
situation assessment} and \emph{online social behaviour generation}) will be
grounded in real-world applications. Indeed, two complex, high impact
applications are detailled in the project. The first one takes place in
Bristol's Children Hospital: a social robot will be permanently deployed in one
of ward, supporting isolated children who suffer long-term conditions, in close
cooperation with the hospital staff. The second one involves the deployment of 
social robots in special need schools (SEN schools) in Bristol. Building on a
rigorous participatory approach involving the school teachers, as well as the
parents, we will seek to integrate the robot in the daily life of the school,
supporting the development of the students' physical and social skills.

These two applications, detailled hereafter, aim at supporting
socially-vulnerable populations: this entails specific risks (detailled and
addressed in the Section~\ref{risks}), but also offers a unique opportunity to
demonstrate in a real-world, impactful case, how social robots can effectively
have a positive, ethical impact, and support in-fine stronger, richer
human-human interactions.



\subsubsection{The case for robot-supported human-human interactions}

While the original aspiration to a
'multi-function-household-robot-that-does-the-dishes' has yet to materialise --
physical manipulation of objects in an unstructured environment is hard, as it
happens --, social robots are certainly in the process of establishing
themselves as important agents in a variety of other situations, for their
intrinsic \emph{social} features: source of comfort, tutors, entertainers. The
robot as a \emph{social agent} is a reality, within laboratories at least.

As a researcher who has been working for the last 12 years in the field of
human-robot interaction (and child-robot interaction in particular), I have been
a direct witness -- through being one of the architects -- of the crossing of a
critical milestone: the emergence of \textbf{durable social interactions}
between robots (artificial intelligent agents) and humans. Over the last two
years in particular, we observe an explosion of the number of studies involving
social robots, deployed in real-world settings (schools, care centres) over
relatively long periods of time (up to 2 or 3 months at a time). Even though
these robots are rarely fully autonomous, they do already show high levels of
autonomy~\cite{emmanuel}, and complete autonomy is in sight as
well~\cite{strands}.\TODO{litt review}

While many see these developments positively, or even as a turning point [...]
other express skepticism or worry that this technology might lead to a
dehumanisation of our society. Indeed, if artificial agents are to engage into
social interactions with us, and enter what many view as a form of a 'private
domain', reserved to humans, pressing ethical questions need to be answered:

\begin{itemize}
    \item how to ensure that social robots are not used to simply replace humans
        (like social workers) to cut costs?
    \item can we guarantee that the use of social robots will always be ethically motivated?
    \item even further, can we implement some ethical safeguarding at the core
        of the system (like an ethical \emph{black-box}~\cite{winfield})?
    \item what about privacy? how to trust that robots in our home or school or
        hospital will not eavesdrop on our private lives, and, in the worst
        case, will not used \emph{against} us?
\end{itemize}

These questions are not only legitimate, but also pressing: the recent rise of
personal assistants like Alexa or Google Home, with the major privacy concerns
that accompanies their deployments in people home, shows that letting the
industry set the agenda on these questions is not wise -- and robots can
potentially be much more intrusive than non-mobile smart speakers.

Social robots have two unique properties which distinguish them from these smart
speakers, and significantly complexify their conceptual framing. First, they are
fully embodied, and they physically interact with their environment, from moving
around, to picking up objects, to looking at you; second, willingly or not, they
are ascribed \emph{agency} by people.  This second difference has far-reaching
consequences, from affective bonding to over-trust, to over-disclosure of
personnal, possibly sensitive, informations [cite paper HRI children
disclosure].



This progress raises questions, both practical and more fundamental:

inventing and building a principled cognitive architecture for tomorrow's social
robots, nutrured by decades of research in understanding human social cognition,
and where ethics and privacy are intrinsic to the system.

Due to the complex interplay between the technical implementation, the
socio-psychological determinants of the interactions, and the multiple ethical
mechanisms that have to be built-in the system, it is difficult to build one
coherent and consistent perspective on the whole question. Indeed, the
conceptual, intellectual framework emcompassing both the internal cognitive
mechanisms required by socially intelligent robots, as well as their role and
impact in the society, only exists in fragmented, disconnected pieces.

The lack of such a proper conceptual framing is a critical issue: for robots to
have a positive impact on the society, with strict ethical and privacy-related
safeguarding, it is urgent that the wider academic and intellectual communities,
beyond technologists, embrace this question and build up the debate on the
acceptability of robots in our society.

As such, the foundational ambitious of \project is to create a conceptual
framework around social robots in the human society, by reframing the widely
accepted, yet sorely unspecific, idea of \emph{human-robot interaction} into the
more specific idea of \emph{robot-supported human-human interactions}: the robot
is considered from the perspective of how it can \emph{support} humans, and in
particular, support stronger, positive interactions between humans.

Critically, though, \project will ground this conceptual frame into the reality
of socio-cognitive AI and real-world deployments of social robots.


\subsubsection{Three pillars}

To achieve the vision of a natural and harmonious \emph{co-habitation} between
social robots and humans, ...

The \project project will, for the first time, take a broad, holistic approach
to these questions, and as such, is build around three pilars:

\begin{enumerate}
    \item AI architecture for decision making
    \item socio-psychological design of the interaction, from 1-to-1
        interaction, to group interaction, to interaction with the eco-system
    \item built-in privacy and ethics
\end{enumerate}

The difficulty comes from the fact that these pilars do not represent independent
research questions: they are deeply woven together, in intricate ways.


Taken independently, these three pilars are already intrinsically complex.

The first pilar, AI Architecture for Decision Making, for instance:
state-of-the-art decision making processes for social robots are build from
multiple algorithmic layers: classical machine learning (like classifiers, or
SLAM) for low-level sensori-motor processing; probabilistic data processing (for
e.g. localisation or point cloud processing); deep neural networks for object
recognition, scene understanding, speech and dialogue processing; classical
symbolic reasoning (for instance, for task planning); high-level knowledge
representation and reasoning (semantic webs); hybrid spatial/symbolic reasoning
for motion planning; etc.

Importantly, these layers are not typically combined in a simple, linear
fashion: modern control architectures are distributed, loosely coupled, and
design so that information flows in multiple directions, at different levels of
abstraction, in order to create complex feedback loops, and achieve systems that are
both goal-directed \emph{and} reactive (event-driven).


The real complexity of such AI architectures is however striking when one tries
to answer \emph{how} such an architecture can enable the realisation of the
desired socio-cognitive functions, i.e. our second pilar. Social behaviours and
social situations are highly dynamic, loosely structured, underspecified (no
pre-made rulebook exists), uncertain.

Our best answer is for the robot to learn to become social: a human expert teaches
the robot how to socially behave, in-situ, with the robot embedded in the
interaction. I have conducted two recent and high-profile experiments in this
direction

\subsection{Evidence-based research: demonstrable usefulness of social robots in
real-world, complex scenarios}

\project aims at developping and demonstrating the need for a global approach to
social HRI with ambitious, high-impact, socially meaningful, applications. Over
the course of the project, I will achieve that aim through two ambitious
applications: the creation and deployment of a robot companion to support
isolated children during their hospital stay, fully integrated and aware of the
hospital ecosystem; the creation and deployment of a small robotic friend to
support young, vulnerable refugees during their asylum-seeking process.

\subsubsection{Scenario 1: A robot companion at the children's hospital}

\subsubsection{Scenario 2: A robot-guide to supporting young asylum seekers in
becoming the tellers of their own stories}

This second application scenario is about using a small, social, friendly robot
to help refugee children to turn the complex experience of their journey across
the world into a powerful story that they will be able to show and tell while
seeking asylum.

The robot (while the exact platform is yet to be decided, it will likely be
similar to the Bluefrog's Buddy or Asus' Zenbo) will be used by field
practitioners (primarily by ArtRefuge UK, with possible extensions to other
charities and NGOs) in refugee camps and safe-houses across Europe to support
the children. Supported by the staff, the robot and the child engage into a
non-threatening social interaction, in which the child is invited, little by
little, to recount her/his journey and personal life. The duration and frequency
of the interventions is flexible and would be tailored to each child's needs;
over the course of one to three weeks, we would typically envision one 30-min
long interaction every day.

Following the ArtRefuge approach, as well as the interactions created by Chloé
Meineck on her previous Trove project\footnote{\url{https://bit.ly/2ZlZL5W}},
the child is invited to tell her/his story in many different way, using a
variety of supports: narration, drawings, paintings, plasticine, small toy
figures, etc.  The robot records (pictures, videos, sounds) these
representations, and also actively engage with the child, showing curiosity,
non-judgmental emotional responses, and nudging the child to tell more, show
more.

Critically, while the robot will be able to understand and record the textual
transcription of the what the child says (multi-lingual speech recognition),
the robot itself is purposefully designed *not* to speak, using instead *non-verbal*
communication mechanisms (non-verbal utterances using sounds, gaze, joint
attention, expressive motions, etc). In particular, the *soundscape* of the
robot will be designed by Dave Meckin, an expert on sound design for vulnerable
children. The purpose is to create an approachable, non-threatening,
non-judgmental, *social* interaction with the child, and effectively establish
the interaction into a trusted physical and emotional *safe-space* for the
child.

The work will initially focus on one-to-one interactions, and might evolve
towards interactions with small groups (2-3) of children if deemed desirable
after the first field deployments.

Another critical aspect of the project relates to how the robot will store and
protect the potentially highly sensitive data that is recorded during the
interactions. Data will only be stored on the robot itself (no external cloud
storage), and records will be strongly encrypted (i.e. even if the robot is
seized, the data will not be accessible). We will research secure, yet
child-friendly, mechanisms to identify the child and ensure that only her/him
can access her/his personal data. This will likely involve a combination of
picture-based passwords and facial recognition.

The created digital record will ultimately belong to the child. We will research
and create practical means (paper copy, bracelet with a SD card,...) for the
child to access this record when he needs it, and take it with her/him, even
after she/he has left the camp or safe-house. The devised solution will have to
ensure that no abuse or misuse of the record against the child is possible.

\subsubsection{Experimental deployments: risks and mitigations}

These two application scenarios are ambitious and risky -- one could argue they
are whole projects in their own right. However, first, demonstrating the
importance of advanced social modelling, and convincingly proving the
effectiveness of our approach does require accordingly complex social
situations, and complex social dynamics. The two scenarios, which complement
each other, provide both.

Second, working with vulnerable populations, in constrained (the hospital) or
difficult environments (refugee camps) adds significant risks to the project.
But it is also what make the project in the unique position of delivering a very
high societal impact: a direct positive impact on children's lives (we
anticipate 100+ hospitalised children and 50+ refugee children interacting over
long periods of time with a robot over the course of the project), and a broader
impact on the society, showing how robots can have a lasting, strong, positive
impact on the society, also establishing the idea of \emph{robots supporting
human interactions} instead of dehumanising our social relationships.

The two main mitigations are (1) early and continuous engagement with the
stakeholders, and (2) the decoupling of the two applications, meaning that the
risks associated to each of them do not impact the other one.

Early engagement will be ensured by relying on a participatory design
methodology, involving all the stakeholders from the onset of the project; the
methodology will involve regular joint workshops; on-site (hospital and refugee
camps) research stay including engagement with the staff/charities and the
children themselves; use of art-based participatory techniques like puppetering.
I will also perform field testing early on in the project, relying if necessary
on provisional robot platforms available at the host institution (for instance,
Softbank Nao and Pepper). This user-centered approach will be championed by one
of the post-doc recruited on the project, who will have recognised expertise in
user-centered design.


The Principal Investigator, Dr.  Séverin Lemaignan, has been working for 12+
years in human-robot interaction, and over the last 6 years, specifically in the
field of child-robot interaction.  His profile is both highly technical, with
hundreds of hardware and software contributions to the worldwide robotic
community; and highly experimental, running dozens of studies and experiments
with children, including long-term ones, in muliple schools and in healthcare
environments. He is in a unique position to deliver both a scientific
breakthrough on social situation assessment for robots, and a high-impact
societal change.

\subsection{The long-term vision: robot-supported human-human interactions}


\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.9\linewidth]{figs/render5-colors.png}
\end{figure}

\project is a project that aims at helping to build strong human
relationships with the help of technology.

The core idea of the project is to build small companion robots whose
aim is to facilitate human-human interactions. We want to develop these
robots with a particular application in mind: supporting the social and
cultural integration of vulnerable children in a foreign country, and in
particular, migrant children who might lack the otherwise needed support
(shared culture; already well integrated relatives) for a successful
integration.

\subsubsection{Key scientific research questions}

\begin{enumerate}
\item research the role of social influence to scaffold positive human-human
    interactions (including its ethical ramifications) in the context of migrant
    integration;
\item explore how a small robot companion can be endowed with social
    competencies to positively influence human interactions; design and
    implement the corresponding artificial social behaviours;
\item design and build a small rugged and autonomous companion robot that
    realise this goal for child-child interactions; test the technology in
    school with actual migrant children.
\end{enumerate}

\subsubsection{Vision of a novel form of interaction ``human-(robot)-human''}

\paragraph{The case of the social integration of migrant children}

A robot is left with the child when he or she starts their journey in
their new host country, and becomes a companion for the child during the
first months of the integration. Using several mechanisms that are
discussed in this proposal, the robot helps the child to gain
self-confidence, and ultimately engage in successful social interactions
with other children.

Critically, the robot is designed to support the social and cultural
integration of the child \emph{amongst her/his peers}. While the child
might build affective/emotional bonds with the robot over the course of
the support period, the robot behaviour is designed to ensure that these
bonds do not substitute themselves to the interactions with other
children.

The project combines a range of scientific and engineering endeavours to
realise within a 5-years timeframe an ambitious and bold vision for
social robotics in our society. Specifically, the project draws from the
fields of social robotics; human-robot interaction; human-machine
interaction design; and mechatronics.

While the breadth of the proposed project is significant (from
mechatronic design to long-term field testing with vulnerable
populations), the project structure minimizes the cross-dependencies
within the project, avoiding critical failure points that would put the
whole project at risk, and a careful risk assessment is conducted that
includes meaningful mitigation strategies.




\subsection{A principled architecture for socially intelligent robots}


\begin{itemize}
    \item Intrinsic social motivation: do good
    \item bottom-up grounding for situation assessment and social situation
        assessment
    \item symbolic grounding of both environment and social situation using
        'human in the loop' OR data-driven symbolic grounding
    \item knowledge representation and symbolic reasoning for dialogue
        grounding, goal planning, knowledge exchange and linked data
    \item action execution using human-in-the-loop ML
\end{itemize}


\subsection{Cross-disciplinary team, research methodology, and research
infrastructure}

The project's ambitious scientific and technical goals are expected to deliver
major scientific, societal and technical impact, that extends beyond the
boundaries of the fellowship. While ambitious, the project's feasibility is
ensured through a strong combination of cross-disciplinary expertise and
support from the host's unique research infrastructure. Scaffolded by a
participatory and iterative research methodology, and the PI experience in
managing teams and complex projects through his recognised leadership, \project
is set to deliver.

\project is indeed an interdisciplinary endeavour, and requires several
complementary expertises to be successfull. I have assembled a strong and
diverse team, with exceptional expertise both on working with vulnerable refugee
populations, and on designing social robots. The team comprises of institutional
partners with strong expertise in supporting asylum seeker (UK Refugee Council
and [Katheryn Cronin - lawyer]), charities with extensive experience using art
to support refugee populations (ArtRefuge UK), an interaction designer working
on memory collection and recollection with vulnerable children, and several
close academic collaboration: with Dave Meckin (University of the West of
England), senior researcher in media tecnologies with a unique expertise working
with vulnerable children; with Jérémy Bonvoisin (University of Bath), senior
research on sustainable and open hardware development; and finally with Katie
Winkle (University of Bristol/University of the West of England), junior
scientist with a unique expertise in social robotics.

To mirror the cross-disciplinary team, the research methodology developped for
\project will rely heavily on \emph{mutual shaping}, through co-design and
participatory design, and multi-disciplinary development sprints.

\subsubsection{Technical infrastructure}

The \project project sets an ambitious target in term of technical development.
The project indeed requires unique technical skills, both software and
hardware-wise, to create, design and build the envisonned robotic systems.

Software-wise, Dr Lemaignan, the principal investigator, is a leading
developer of software for intelligent robots, with numerous contributions to
the major software platforms used in robotic (including major contributions to
ROS, OpenCV, authoring of widely-used pieces of software like the ROS-naoqi
bridge used by hundred of researchers using the Nao and Pepper robots or the
MORSE robotic simulator). He has been teaching various modules related to
software development for robotics, and the breadth and depth of his knowledge of
robotic software development is well established. He will be leading the
software development, and, as part of the fellowship, he will also seek for
additional expert knowledge on (1) interaction design and (2) low-level
micro-programming to complete the set of required programming needs.

Hardware-wise, the Bristol Robotics Lab, where this fellowship will take place,
offer unique support and facilities for robotic hardware development: the
laboratory's dedicated equipment includes two industrial-grade rapid prototyping
machine, a laser cutter, one 5-axis digital milling machine, all the required
facilities for PCB prototyping, and a team of six full-time technicians,
specialised in hardware development. The BRL has indeed a long track-record of
designing and building new and original robots (from the BERT humanoid in the
FP7 CHRIS project, to micro-robotics [in...?], to [...]). \project will directly
benefit of this expertise, which will ensure a feasible and realistic technical
implementation of the \project robots. Besides, an hardware engineer, dedicated
to the project, will be recruited in the frame of the project.

The BRL also include a hardware incubator and is co-located with 70 start-ups
and SMEs specialising in robotic hardware and mechatronics (Bristol's
\emph{FutureSpace}). This combination of excellent research and vast industry
expertise on one site is unique in the UK, and is will play an instrumental role
in providing a coherent and strong pathway to impact to the project, including
further engagement with industrial partners and spin-off opportunities.



\newpage

\printbibliography




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\section{B1.b The principal Investigator}\label{the-principal-investigator}

\hypertarget{curriculum-vitae}{%
\subsection{Curriculum vitae}\label{curriculum-vitae}}

\eu{(max 2 pages)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\subsection{B1.2 Early achievements track-record}\label{early-achievements-track-record}

\eu{(max 2 pages)}

Dr Séverin Lemaignan is Senior Researcher at the Bristol Robotics
Laboratory, University of the West of England, Bristol. Previously, he
obtained a joint PhD in Cognitive Robotics from the CNRS/LAAS (France)
and the Technical University of Munich (Germany) for which he received
the Best PhD in Robotics 2012 award from French CNRS. He then conducted
his research as Research Fellow at EPFL (Switzerland) and Plymouth
University (UK) where he was Lecturer in Robotics until 2018. Dr Séverin
Lemaignan has been involved in several European projects related to
social and cognitive robotics: CHRIS (Cooperative Human Robot
Interaction Systems), DREAM (Development of Robot-Enhanced therapy for
children with AutisM spectrum disorders), L2TOR (Second language
TutOring using social Robots). He has also been awarded in 2015 a EU
H2020 Marie Sklodowska-Curie Individual Fellowship for his project
DoRoThy (Donating Robots a Theory of Mind). His research interests
primarily concern the socio-cognitive aspects of human-robot
interaction, both from the perspective of the human cognition and the
design of cognitive architectures for the robots. More recently, he has
been focusing his experimental work on child-robot interactions in
educative settings, exploring how robots can support teachers and
therapists to develop effective and engaging novel learning paradigms.
















%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage

\section{B2. The scientific proposal}\label{part-b2-the-scientific-proposal}

\eu{(max 15 pages)}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Novelty, non-incrementality, plausibility and foundational character}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Companion robots}

One example of a small, rugged robot designed for intensive use in school
environments is Cellulo~\footcite{ozgur2017cellulo}.

\begin{figure}[!htbp]
    \begin{minipage}[b]{.3\linewidth}
        \centering\includegraphics[height=4cm]{figs/cellulo.jpg}
        \subcaption{EPFL's Cellulo robot}\label{fig:cellulo}
    \end{minipage}%
    \hspace{0.5cm}
    \begin{minipage}[b]{.3\linewidth}
        \centering
        \includegraphics[height=4cm]{figs/tega.jpg}
        \subcaption{MediaLab's Tega robot}\label{fig:tega}
    \end{minipage}
    \hspace{0.5cm}
    \begin{minipage}[b]{.3\linewidth}
        \centering
        %\includegraphics[height=4cm]{figs/ono.png}
        \subcaption{OPSORO's Ono robot}\label{fig:ono}
    \end{minipage}
    \caption{Existing research-level companion robots}\label{fig:research-robots}
\end{figure}

\begin{figure}[!htbp]
    \begin{minipage}[b]{.3\linewidth}
        \centering\includegraphics[height=4cm]{figs/miro.jpg}
        \subcaption{Consequential's Miro robot}\label{fig:miro}
    \end{minipage}%
    \hspace{0.1cm}
    \begin{minipage}[b]{.3\linewidth}
        \centering
        \includegraphics[height=4cm]{figs/hatchnimals.jpg}
        \subcaption{SpinMaster's Hatchimals}\label{fig:hatchimals}
    \end{minipage}%
    \hspace{0.1cm}
    \begin{minipage}[b]{.3\linewidth}
        \centering
        \includegraphics[height=4cm]{figs/anki-vector.jpg}
        \subcaption{Anki's Vector}\label{fig:vector}
    \end{minipage}
    \caption{Existing commercial companion robots}\label{fig:commercial-robots}
\end{figure}



\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{figs/wizme+dolls}
    \caption{Early prototyping for the \project: a pet-like robot that could
    mediate child-child interactions}
    \label{}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Social situation assessment}

\begin{figure}
\centering
\includegraphics[width=0.9\linewidth]{images/archi}
\caption{Overview of the technical architecture enabling social situation
    assessment: social situation assessment builds on strong \emph{situation
    assessment}, on top of which humans and human interactions are layered.}
\label{fig:social-situation-assessment}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Social influence}

\begin{figure}[!htbp]
\centering
    \includegraphics[width=0.7\textwidth]{figs/cozmo-expression-sheet.jpg}
\caption{Cozmo facial expressions}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Research methodology}\label{research-methodology}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Data-driven continuous behaviour generation}


At a time where companion robots are coming to the market, one important
question remains fully open: how to design robot behaviours that foster
lasting engagement? A vast body of academic literature identifies that
robots evoke an initial phase of high user engagement (the
\emph{novelty} phase) that vanishes as the user realises that the robot
is actually quite predictable and repetitive. The \emph{agency}
initially ascribed by the user to the robot quickly fades (Lemaignan et
al. 2014), leading to critical user disengagement from the technology.

%\begin{wrapfigure}[23]{l}{6.5cm}
\begin{figure}
    \centering
    \includegraphics[width=0.5\paperwidth]{figs/husky.jpg}
    \caption{\label{fig:robot}
    Provisional appearance of the \project robot that we ill use to collect
    data. A tablet, displaying facial animations, is mounted on a robotic arm.
    It can freely orient its `gaze' and use expressive movements. The mobile
    base (a Segway Husky) can autonomously navigate in the various parts of the
    BRL open-space}
\end{figure}
%\end{wrapfigure}

The (often limited) library of behaviours available to the robot is
often cited as a key factor in causing this issue. However, another,
more profound issue affecting long term engagement with robot companions
is the question of \emph{purpose.} Without clear \emph{purpose}, social
robot companions can lack \emph{usefulness}. Indeed, robot
\emph{companions} might not have explicit goals that would dictate or
motivate their behaviours: they aim at providing a social presence, a
social comfort, as cats or dogs would do, without necessarily being
goal-oriented.

Recent attempts -- and failures -- to convert social robotics research
into commercial platforms (Jibo, Kuri and most recently Anki's Cozmo and
Vector robots) reflect exactly this, with reasons for their failure
typically citing an under-delivery of the user experience they promised,
and/or the lack of a `real need' to justify their price point. The
\project project addresses these two key issues by:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Taking inspiration from human-pet relationships which also have no
  explicit \emph{purpose} beyond their potential for enjoyable,
  \emph{affective} interactions;
\item
  Working with creative professionals who excel at storytelling and
  emotional engagement to overcome the problems in sustaining
  engagement, as proposed by Hoffman\footnote{\url{https://spectrum.ieee.org/automaton/robotics/home-robots/anki-jibo-and-kuri-what-we-can-learn-from-social-robotics-failures}};
\item
  Blending these two sources of inspiration using a radically novel
  combination of immersive teleoperation and machine learning.
\end{enumerate}

The project is \emph{not} about replicating a pet's behaviour per se. It
is instead about identifying, modeling and automatically generating the
social behaviours required to recreate pet-like social dynamics between
robots and humans, drawing inspiration from ethology (Stanton, Sullivan,
and Fazio 2015). Using animal behaviours to inform the design of robots
is not new, the most remarkable example being the Sony AIBO robot dog,
whose behaviours were directly designed around those of actual dogs
(Arkin et al. 2003). However, to go beyond the repetitive interactions
associated with such robots, we propose to employ a creative
professional to actively participate in design and automation of \project
behaviour. The concept of using creative professionals to `teach' social
robot behaviour is not new either (Knight and Gray 2012), however it is
only recent advances in human-in-the-loop, online machine learning that
make this type of real-time `social training' a feasible approach to
generating and automating engaging social behaviours (Senft et al.
2019).

Our project has the following goals, addressed by the workplan presented
below:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  assemble a non-anthropomorphic social robot that can autonomously
  navigate in a complex and living lab environment, taking inspiration
  from ethology to inspire the robot's behaviour;
\item
  develop an immersive teleoperation system, enabling a creative
  professional to `take control' of the robot (i.e.~puppet the robot) in
  a completely intuitive way (using whole body motion tracking);
\item
  record (and make publicly available) a large dataset of social
  behaviours (created through immersive teleoperation) that foster
  long-term social and affective engagement. The dataset will also
  include the social \emph{signals} implicitly used by the puppeteer to
  drive his/her choice of actions (recorded through eg eye-tracking);
\item
  using machine learning, map these social signals (input state) to the
  robot behaviours (output state) such that the robot can operate
  autonomously.
\end{enumerate}

A creative professional (puppeteer, dancer or comedian --
corresponding financial compensation is budgeted) will join the group.
First she/he will take part to a one-week co-design workshop (4) aiming
at finalising the immersive teleoperation controller and the behaviours
of the robot. Then, she/he will interact for about 4 hours a day during
a month, with the BRL lab members (200+ researchers). She/he will do so
by remotely operating the robot (5) from an (out-of-sight) control room
(the BRL CAVE room). The aim will be for the puppeteer to pro-actively
engage with people in the lab, attempting to engage in \emph{social,
affective} interactions. This will be achieved by creating/inventing
in-situ a new `grammar' of social behaviour, loosely inspired by those
of cats and other pets. These interactions will be fully recorded
(including eye-tracking on the puppeeter) (6), in order to create a
unique dataset of complex social interactions, suitable for machine
learning. The PI has already extensive experience in recording such
datasets (see (Lemaignan et al. 2018) for instance).

%\begin{wrapfigure}[17]{l}{8cm}
\begin{figure}
    \centering
    \includegraphics[width=0.8\paperwidth]{figs/dev.pdf}
    \caption{\label{fig:support}
    Social behaviours will be learned from immersive `puppetering' of the
    robot, performed by a professional actor. The `puppetering' takes place
    in a CAVE (or VR) environment, where what the robot `sees' and `hears'
    is streamed live}
\end{figure}
%\end{wrapfigure}

Over the following four months, a deep neural network will be designed
and trained (7) for the regression task of generating continuous social
behaviours from perceived social signals. In parallel, a software
controller will be developed (8) to enable generic autonomous
capabilities (like autonomous navigation) for which the BRL has
extensive expertise.

Finally, the last four months will be dedicated to in-situ testing of
the autonomous system (9). We will seek to conduct a large scale study
within the lab, over a period of several weeks. For this study, the
robot is expected to be fully autonomous. However sufficient amount of
time is planned for additional iterations on the development of the
robot controller if deemed necessary. We aim at publishing the results
of this main study shortly after the end of the one-year period.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Deployments in schools}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Interdisciplinarity}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\section{Impact}\label{impact}

\subsection{Impact on society and technology: building an inclusive society}


\project will deliver new and fundamental knowledge to the fields of robotics,
computer science and psychology, in addition to improving trans-disciplinary
understanding between these disciplines. More specifically, the project will
contribute to a better understanding of the following research areas:
human-robot interaction; human-machine interaction; human error making and
handling in assembly tasks; theory of mind and its transfer to cognitive robots;
natural language processing; explainability and language generation; machine
vision and human activity detection; and action planning under uncertainty. New
interaction paradigms will be developed for handling error situations where
machines interact with non-expert humans. The integration of perception and
sensing into cognitive robot architectures will be critically reviewed and
extended. Novel, empirically informed methods to transfer findings from
human-human interaction studies to human-machine interactions will be developed.
Furthermore, the national and international psychology, robotics and computer
science research communities will benefit from the project results. We will
publish \project results in interdisciplinary and discipline-specific journals
and conferences, and organise \project-themed workshops. Please refer to Section
\ref{sec:impact} about our concrete action plan to maximise impact. 




Academically, the \project project represents a timely combination of
very recent advances in supervised machine learning for social robot
behaviour with a creative and interdisciplinary approach to the design
and automation of social robot behaviour. We therefore expect to publish
results in high-class scientific journals and conferences.

The dataset of social behaviours and social signals we will create and
distribute represents a one-in-a-kind resource for the human robot
interaction community, and the human data collection will be
transferable to research in other domains such as human-computer
interaction.

As \project will be deployed in a living lab environment, there is
significant scope for public outreach/engagement and media coverage,
which we will work with the BRL's media manager to maximise.

\subsection{Impact on future leadership}

\subsection{Measures for achieving impact}

\subsubsection{Dissemination and exploitation of results}

\subsubsection{Communication activities}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Implementation}\label{part3}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Names of the Work packages

\newcommand{\wpOne}{Project management}
\newcommand{\wpOneShort}{\wpOne{}}

\newcommand{\wpTwo}{Technology to socially influence human-human interactions}
\newcommand{\wpTwoShort}{Social influence}


\newcommand{\wpThree}{Interaction design for robot-supported human-human interactions}
\newcommand{\wpThreeShort}{Interaction design}

\newcommand{\wpFour}{Design and building of a companion robot for social interaction in the field}
\newcommand{\wpFourShort}{Companion robot creation}

\newcommand{\wpFive}{AI for social cognition}
\newcommand{\wpFiveShort}{AI for social cognition}

\newcommand{\wpSix}{Dissemination and exploitation}
\newcommand{\wpSixShort}{Dissemination}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Workplan and intermediate targets}

\subsubsection{Project structure}

\begin{table}[!htbp]
    \begin{tabular}{@{}p{1cm}p{6cm}p{2cm}p{2cm}p{1.5cm}p{1.5cm}p{1.5cm}@{}}
\toprule
\textbf{WP} & \textbf{Work package title} & \textbf{Lead participant No} & \textbf{Lead participant short name} & \textbf{Person-Months} & \textbf{Start month} & \textbf{End month} \\ \midrule
1                        & \wpOne                      &                              &                                      &                        &                      &                    \\
2                        & \wpTwo                      &                              &                                      &                        &                      &                    \\
3                        & \wpThree                    &                              &                                      &                        &                      &                    \\
4                        & \wpFour                     &                              &                                      &                        &                      &                    \\
5                        & \wpFive                     &                              &                                      &                        &                      &                    \\
6                        & \wpSix                      &                              &                                      &                        &                      &                    \\
                         &                             &                              &                                      & \textbf{Total months}  &                      &                    \\ \bottomrule
\end{tabular}
\end{table}


\subsubsection{Work package 1: \wpOne}

\begin{table}[!htbp]
\centering
\begin{tabular}{|l|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|}
\hline
Work package number            & 1 & \multicolumn{3}{l|}{Lead beneficiary} & \multicolumn{3}{l|}{\bf BRL} \\ \hline
Work package title             & \multicolumn{7}{l|}{\wpOne}                                             \\ \hline
Participant number             &     &         &         &                  &       &       &      \\ \hline
Short name of participant      &     &         &         &                  &       &       &      \\ \hline
Person/months per participant: &     &         &         &                  &       &       &      \\ \hline
Start month                    & \multicolumn{3}{l|}{}  & End month        & \multicolumn{3}{l|}{} \\ \hline
\end{tabular}
\end{table}


\textbf{Objectives:}

\textbf{Description of work:}

\ldots{}description\ldots{}

\task{1.1}{}

\vspace{0.5cm}\textbf{Deliverables:}

\begin{itemize}

\item   \emph{Deliverable D1.1} (Month 2): website and logo
\end{itemize}

\subsubsection{Work package 2: \wpTwo}

\begin{table}[!htbp]
\centering
\begin{tabular}{|l|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|}
\hline
Work package number            & 2 & \multicolumn{3}{l|}{Lead beneficiary} & \multicolumn{3}{l|}{} \\ \hline
Work package title             & \multicolumn{7}{l|}{\wpTwo}                                       \\ \hline
Participant number             &     &         &         &                  &       &       &      \\ \hline
Short name of participant      &     &         &         &                  &       &       &      \\ \hline
Person/months per participant: &     &         &         &                  &       &       &      \\ \hline
Start month                    & \multicolumn{3}{l|}{}  & End month        & \multicolumn{3}{l|}{} \\ \hline
\end{tabular}
\end{table}

\textbf{Objectives:}
\textbf{Description of work:}

\ldots{}description\ldots{}

\task{2.1}{Identification of the dimensions of social influence for human interpersonal interactions}

\task{2.2}{Ethics of social influence}
Blah blah

\task{2.3}{Study 1 -- Socially influencing companion robot}
First study, using Anki's Vector robot.

\vspace{0.5cm}\textbf{Deliverables:}

\begin{itemize}
    \item \D{2.1}{12}{great report}
\end{itemize}

\subsubsection{Work package 3: \wpThree}

\begin{table}[!htbp]
\centering
\begin{tabular}{|l|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|}
\hline
Work package number            & 3 & \multicolumn{3}{l|}{Lead beneficiary} & \multicolumn{3}{l|}{} \\ \hline
Work package title             & \multicolumn{7}{l|}{\wpThree}                                     \\ \hline
Participant number             &     &         &         &                  &       &       &      \\ \hline
Short name of participant      &     &         &         &                  &       &       &      \\ \hline
Person/months per participant: &     &         &         &                  &       &       &      \\ \hline
Start month                    & \multicolumn{3}{l|}{}  & End month        & \multicolumn{3}{l|}{} \\ \hline
\end{tabular}
\end{table}

\textbf{Objectives:}

\begin{itemize}
    \item refine interaction modalities (in
    particular, the non-verbal speech), details cross-modal interactions,
    define interaction patterns with the child
\end{itemize}

\ldots{}description\ldots{}

\task{3.1}{Analysis of needs}
\task{3.2}{Cross-cultural interactions}

\vspace{0.5cm}\textbf{Deliverables:}

\begin{itemize}
    \item \D{3.1}{12}{great report}
\end{itemize}

\subsubsection{Work package 4: \wpFour}

\begin{table}[!htbp]
\centering
\begin{tabular}{|l|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|}
\hline
Work package number            & 4 & \multicolumn{3}{l|}{Lead beneficiary} & \multicolumn{3}{l|}{} \\ \hline
Work package title             & \multicolumn{7}{l|}{\wpFour}                                      \\ \hline
Participant number             &     &         &         &                  &       &       &      \\ \hline
Short name of participant      &     &         &         &                  &       &       &      \\ \hline
Person/months per participant: &     &         &         &                  &       &       &      \\ \hline
Start month                    & \multicolumn{3}{l|}{}  & End month        & \multicolumn{3}{l|}{} \\ \hline
\end{tabular}
\end{table}


\begin{itemize}
    \item long term interaction
    \item one full day of autonomy
    \item rugged \footcite{ozgur2017cellulo, hostettler2016realtime}
    \item child friendly: mechanical constraints~\footcite{ozgur2016permanent} + design
\end{itemize}


\textbf{Description of work:}

Develop a novel platform, including:

\begin{itemize}
    \item chassis
    \item power autonomy for one day
    \item on-board compute suitable for deep learning (NVidia Xavier?)
    \item vision (embedded RGB-D camera)
    \item audio processing
\end{itemize}

\ldots{}

\task{4.1}{Physical design of the robot companion}
\task{4.2}{Interaction design}
\task{4.3}{Mechatronics \& Sensing}
\task{4.4}{On-board data processing}
\task{4.5}{System integration}

\begin{itemize}
    \item \D{4.1}{12}{great report}
\end{itemize}

\subsubsection{Work package 5: \wpFive}

\begin{table}[!htbp]
\centering
\begin{tabular}{|l|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|}
\hline
Work package number            & 5 & \multicolumn{3}{l|}{Lead beneficiary} & \multicolumn{3}{l|}{} \\ \hline
Work package title             & \multicolumn{7}{l|}{\wpFive}                                      \\ \hline
Participant number             &     &         &         &                  &       &       &      \\ \hline
Short name of participant      &     &         &         &                  &       &       &      \\ \hline
Person/months per participant: &     &         &         &                  &       &       &      \\ \hline
Start month                    & \multicolumn{3}{l|}{}  & End month        & \multicolumn{3}{l|}{} \\ \hline
\end{tabular}
\end{table}


\textbf{Objectives:}

\textbf{Description of work:}

\ldots{}description\ldots{}

\task{5.1}{Multi-modal communication}
\task{5.2}{Social awareness}
\task{5.3}{Machine learning of social behaviours}
\task{5.4}{Social controller}

\vspace{0.5cm}\textbf{Deliverables:}

\begin{itemize}
    \item \D{5.1}{12}{great report}
\end{itemize}

\subsubsection{Work package 6: \wpSix}

\begin{table}[!htbp]
\centering
\begin{tabular}{|l|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|}
\hline
Work package number            & 6 & \multicolumn{3}{l|}{Lead beneficiary} & \multicolumn{3}{l|}{} \\ \hline
Work package title             & \multicolumn{7}{l|}{\wpSix}                                       \\ \hline
Participant number             &     &         &         &                  &       &       &      \\ \hline
Short name of participant      &     &         &         &                  &       &       &      \\ \hline
Person/months per participant: &     &         &         &                  &       &       &      \\ \hline
Start month                    & \multicolumn{3}{l|}{}  & End month        & \multicolumn{3}{l|}{} \\ \hline
\end{tabular}
\end{table}


\textbf{Objectives:}

\textbf{Description of work:}

\ldots{}description\ldots{}

\task{6.1}{Academic dissemination}
\task{6.2}{General public dissemination}
\task{6.3}{Commercial exploitation}

\vspace{0.5cm}\textbf{Deliverables:}

\begin{itemize}
    \item \D{6.1}{12}{website and logo}
\end{itemize}

\subsubsection{Deliverables overview}\label{deliverables-overview}

\begin{table}[!htbp]
\caption{List of deliverables}
\begin{tabular}{@{}lllllll@{}}
\toprule
\textbf{Deliverable} & \textbf{Deliverable name} & \textbf{Work package No} & \textbf{Lead participant short name} & \textbf{Type} & \textbf{Dissemination level} & \textbf{Delivery date} \\ \midrule
D1.1                 &                           &                          &                                      &               &                              &                        \\
D1.2                 &                           &                          &                                      &               &                              &                        \\
D2.1                 &                           &                          &                                      &               &                              &                        \\
...                  &                           &                          &                                      &               &                              &                        \\ \bottomrule
\end{tabular}
\end{table}

Type:

\begin{itemize}

\item   R: Document, report (excluding the periodic and final reports)
\item   DEM: Demonstrator, pilot, prototype, plan designs
\item   DEC: Websites, patents filing, press \& media actions, videos, etc.
\item   OTHER: Software, technical diagram, etc.
\end{itemize}

Dissemination level:

\begin{itemize}

\item   PU = Public, fully open, e.g.~web
\item   CO = Confidential, restricted under conditions set out in Model Grant
  Agreement
\item   CI = Classified, information as referred to in Commission Decision
  2001/844/EC.
\end{itemize}

\subsubsection{Gantt chart}\label{gantt-chart}

\begin{landscape}
\include{gantt}
\end{landscape}

\subsubsection{Workpackage interrelations}\label{workpackage-interrelations}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.8\linewidth]{figs/wp-interrelations}
    \caption{Inter-dependencies between work packages and main tasks}
    \label{}
\end{figure}



\subsection{Management structure, milestones and procedures}\label{management-structure-milestones-and-procedures}

\subsubsection{Milestones}\label{milestones}

\begin{itemize}

\item   week-long tests with local children in local schools
\item   field deployment with one child in one school
\end{itemize}

\begin{table}[!htbp]
\caption{List of milestones}
\centering
\begin{tabular}{@{}lllll@{}}
\toprule
\textbf{Milestone number} & \textbf{Milestone name} & \textbf{Related work package(s)} & \textbf{Estimated date} & \textbf{Means of verification} \\ \midrule
                          &                         &                                  &                         &                                \\
                          &                         &                                  &                         &                                \\
                          &                         &                                  &                         &                                \\
                          &                         &                                  &                         &                                \\ \bottomrule
\end{tabular}
\end{table}


\subsubsection{Risks}\label{risks}

\begin{table}[!htbp]
\caption{Identified risks and proposed mitigations}
\centering
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Description of risk} & \textbf{Work package(s) involved} & \textbf{Proposed risk mitigation measures} \\ \midrule
risk 1 (low/medium/high)     &                                   &                                            \\
                             &                                   &                                            \\
                             &                                   &                                            \\
                             &                                   &                                            \\ \bottomrule
\end{tabular}
\end{table}





\begin{itemize}
    \item week-long tests with local children in local schools
    \item field deployment with one child in one school
\end{itemize}


Plan to hire one mechatronics engineer and one interaction designer

Role of the mechatronics engineer: develop a novel platform, including -
chassis - power autonomy for one day - on-board compute suitable for
deep learning (NVidia TX2?) - vision (embedded RGB-D camera) - audio
processing

Role of the interaction designer: refine interaction modalities (in
particular, the non-verbal speech), details cross-modal interactions,
define interaction patterns with the child

\hypertarget{measuring-how-effective-the-project-is}{%
\subsubsection{Measuring how effective the project
is}\label{measuring-how-effective-the-project-is}}






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\hypertarget{risk-assessment}{%
\subsubsection{Risk assessment}\label{risk-assessment}}

\hypertarget{c.-resources}{%
\subsection{c. Resources}\label{c.-resources}}

\hypertarget{host-institution}{%
\subsubsection{Host institution}\label{host-institution}}

The \emph{Bristol Robotics Laboratory (BRL)} is the largest co-located
and most comprehensive advanced robotics research establishment in the
UK. It is a joint venture between the University of the West of England
and the University of Bristol. BRL's multidisciplinary approach aims to
create autonomous devices capable of working independently, with each
other, or with humans. BRL draws on robotics, electrical \& mechanical
engineering, computer science, psychology, cognitive science and
sociology. BRL has an international reputation as a leading research
centre in advanced robotics research and has over 250 researchers
working on a broad portfolio of topics: HRI, collective robotics, aerial
robotics, neuro-inspired control, haptics, control systems, energy
harvesting and self-sustaining systems, rehabilitation robotics, soft
robotics and biomedical systems. BRL has many collaboration
partnerships, both national and international, and is experienced in
managing large multi-site projects. BRL has support from two embedded
units specialising in business and enterprise, together with an
incubator and successful track record of spin-outs.

\newpage

\hypertarget{references}{%
\section{References}\label{references}}

\end{document}
