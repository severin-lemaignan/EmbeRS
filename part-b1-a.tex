
\newrefsection

%\textbf{B1.a. Extended Synopsis of the scientific proposal}

\chapter{B1.a. Extended Synopsis of the scientific proposal}\label{part1}

\eu{(max 5 pages)}

\eu{The Extended Synopsis should give a concise presentation of the scientific
proposal, with particular attention to the ground-breaking nature of the
research project and the feasibility of the outlined scientific approach.
Describe the proposed work in the context of the state of the art of the field.
References to literature should also be included. References do not count
towards the page limits. It is important that this extended synopsis contains
all essential information including the feasibility of the scientific proposal
since the panel will only evaluate Part B1 at step 1.}

\section{Long-term vision and ground-breaking nature of the project}

\subsection{Vision and core contribution}

AI and robots are emerging as key factors to successfully address modern societal
challenges, like the ageing society or increasing social isolation. In this
context, researchers in social robotics have the prime responsibility to ensure
that robots can understand and reason about their spatial and social environment
in such a way as to ensure a responsible and positive societal impact.

The basic idea of \emph{social robots} refers to robots that are situated in a
human social environment. In this context, we expect social robots to exhibit
\emph{social awareness}, i.e. to appraise and maintain a model of the social
situation in which they are embedded. Depending on the role of the robot, this
might include understanding who is present, who is interacting with whom, which
are the resulting groups,  what are the in-group roles,  etc.

Social awareness, as a socio-cognitive skill, is essential for the robot to e.g.
act in a context-sensitive manner; reason and apply social norms (for instance,
do not navigate in the middle of a group, or do not suddenly interrupt a
conversation); or create proactive social agents (in order to acknowledge and
respond to a human who would like to engage with the robot, the robot must first
adequately model and recognise the corresponding social situation).


\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{figs/social-embeddings}
    \caption{General principle of social embeddings: arbitrary social situations
    are projected into real-valued vector space, \emph{embedding} their
    semantics. In this example (and assuming the perspective of the yellow
    character), scenes A and B  are more similar to each others (one person walking towards the
    character, with an independent group of people chatting in the background),
    than B and C (in C, the character is already engaged in an interaction).
    Social embeddings make it possible to compare such social situations using
    a simple distance between vectors.}
    \label{fig:social-embeddings}
\end{figure}

This can only be achieved if robots are endowed with the ability to represent
not only their physical environment, but also their social environment and
context. The \project project aims at designing, implementing and characterising
a radically novel method to achieve this goal, based on the concept of
\emph{embedding}: a low-dimensional, semantics-preserving, mathematical
representation of a high-dimensional input (Figure~\ref{fig:social-embeddings}).
Starting from a proof-of-concept of \emph{social embeddings} that I recently
published~\cite{lemaignan2024social}, \project develops and fully characterise
the concept of \emph{social embeddings}, that applies, for the first time, the
idea of building a compact numerical representation to the complexity of social
interactions and social dynamics.


\subsection{Structure of the research programme}

\project is built around three axes: a basic research programme; an experimental
programme that looks specifically at the application of social embeddings to
social robotics; and, running in parallel to those first two axes, a scientific
investigation of the ethical dimension of social embeddings.

At the basic research level, \project targets the following
two overarching research goals: (1) build compact, yet semantics-preserving,
embeddings to represent arbitrary social and spatial environments for service
robots; fully characterize these embeddings, including their latent semantics;
(2) precisely frame the \emph{social awareness} enabled by social embeddings,
and demonstrate the key novel socio-cognitive capabilities that they enable.

I translate these two goals into six operational research objectives:

\begin{center}
    \includegraphics[trim=0 0 0 0, clip,width=0.3\linewidth]{objectives}
\end{center}

\begin{enumerate}[label=\textbf{O\arabic*}]
    \item \label{T1} acquire and analyse a large dataset of real-world human
        interactions to identify a set of prototypical
        social situations; these will serve both for embedding fine-tuning, and
        as reference to analyse the topology and latent semantics of the social
        embedding space;

    \item \label{T2} study social dynamics by characterizing the trajectories of
        on-going social situations in the embedding space. I will look in
        particular into trajectories \emph{discontinuties}, that might represent
        unexpected changes of social dynamics, possibly a predictor of
        interaction failures, and social situation predictions, by extrapolating
        trajectories in the embedding space;

    \item \label{T5} because social embeddings also lend themselves to encoding
        task and social \emph{context} by simply attaching textual descriptions
        of the context, they open new possibilities for
        \emph{context-aware} representation and behaviour selection;


    \item \label{T3} as vector representations, social encodings lend
        themselves well to many downstream machine learning tasks
        that I will explore. For instance automatic engagement
        detection or socially-appropriate behaviour generation using Generative
        Adversarial Networks;

    \item \label{T4} contextualised lifelong adaptation of the robot's
        behaviours, by augmenting existing interactive machine learning
        techniques (`user in-the-loop' social learning, that I pioneered in
        social robotics\cite{senft2017supervised,
        winkle2020couch,winkle2021leador}) with representations of the social
        environment;

    \item \label{T6} finally, and because the development of
        socially-intelligent robots has complex ethical ramifications --
        including the potential of alienating human users --, \project also
        includes a strong research component on Responsible Robotics. In
        particular, the project will aim to contribute directly to the roadmap
        for Responsible Robotics, specifically investigating the interplay between
        machine learning applied to social robotics, transparency and human agency.

\end{enumerate}

These six objectives are reflected in the work package structure of the project,
presented in the next section.


\section{Feasibility of the project}


\subsection{Research team skills}
\label{research-team}

My expertise is primarily centered on cognitive robotics and human-robot social
interaction. My expertise in this field covers a broad spectrum, from basic
research (for
example~\cite{lemaignan2014dynamics,lemaignan2015mutual,irfan2018social,winkle2019effective,bartlett2019what}),
to technical contributions (for instance~\cite{lemaignan2010oro,
lemaignan2017artificial, lemaignan2018underworlds})
to extensive experimental work (for instance~\cite{hood2015cowriter,winkle2020couch,
lemaignan2022social}).

Over the last 4 years, I have re-focalised my work on \emph{data-driven HRI},
contributing several new large datasets of social
interactions~\cite{lemaignan2018pinsoro,sallami2020unexpected,webb2023sogrin},
developing new data analysis
techniques~\cite{bartlett2019what,webb2022measuring}, and demonstrating with my
students new applications of interactive machine learning to social
interactions~\cite{senft2016sparc,winkle2020couch,winkle2021leador}.
In parallel, I progressively matured the idea of computing compact
\emph{embeddings} of social situations, until I published in 2023 a first
breakthrough in that direction~\cite{lemaignan2024social}. This ERC project is
directly born from this multi-year endeavour towards data-driven HRI, and aims
at significantly accelerate research in this direction.

In particular, \project is the opportunity to gather an interdiscplinary team of
academics that would effectively complement my expertise, and ensure the
feasibility of the project.

Specifically, I intend to recruit:

\begin{itemize}
    \item two researchers with expertise in large language models (one senior
        post-doc, one PhD student);

    \item  two researchers with expertise in sociology and/or data-driven
        sociology (one senior post-doc, one PhD student);

    \item one researcher with expertise in ethics of technology (post-doc level)
\end{itemize}


\subsection{Feasibility of the experimental program}


The experimental program is usually the more complex to run. For \project, it
relies on (1) having the requested AI software ready; (2) implementing the AI
software on an actual robotic platform; (3) deploy the robot in real-world
public spaces, with the associated practical know-how.

Regarding item (1): using publicly available resources, including machine learning architectures
like Transformers, an state-of-art open-source pre-trained Large Language
Models, so-called \emph{foundational models} like
Llama2~\cite{touvron2023llama}, I have shown in~\cite{lemaignan2024social} that
social embeddings can indeed already be generated in near-real time on consumer-grade
GPUs. The integration of social embeddings in a larger cognitive architecture
suitable for social robots will require extending existing architectures, of
which I have extensive experience~\cite{lemaignan2017artificial,
lemaignan2015pyrobots,baxter2016cognitive,lemaignan2014challenges,lemaignan2011what}.

\begin{wrapfigure}[11]{l}{0.15\linewidth}
    \centering
    \vspace{-10pt}
    \includegraphics[width=\linewidth]{tiagopro}
    \label{fig|tiagopro}
\end{wrapfigure}

Regarding item (2), the deployment on actual hardware: as \project focuses specifically on the
\ul{AI engine} of the robot, I will use an existing, off-the-shelf, social
robot, most likely a PAL Robotics TIAGoPro (pictured on the left). TIAGoPro offers
out-of-the-box advanced human perception based on the ROS4HRI framework, that I
originally designed~\autocite{mohamed2021ros4hri} as an international standard for
Human-Robot Interaction~\autocite{lemaignan2022ros}. It also offers on-board GPU
options that are appropriate to implement a fully AI-based autonomous system.
I have extensive experience with this platform, having actually directly taken part to
its design and software stack implementation while employed at PAL Robotics.

Finally, regarding experience with deploying robots and fieldwork know-how, I
have a long-track record. From studies in
schools~\cite{hood2015when, lemaignan2016learning, jacq2016building,
baxter2015wider,kennedy2016cautious,senft2018robots,lemaignan2022social},
at people's home~\cite{mondada2015ranger}, in public
spaces~\cite{alhafnawi2022deliberative}, or in healthcare environments
(including hospitals and care home)~\cite{winkle2020couch,cooper2023challenges}, I have conducted 20+
deployments of social robots in real-world environments, ranging from a few
days, to several weeks~\cite{jacq2016building,lemaignan2022social} or
months~\cite{winkle2020couch}.

As such

Indeed,
after an initial training period, the robot will be \emph{autonomous}: while the
users will be provided tools to override the robot decisions at any time (via
both an app and touch sensors on the robot itself), it will otherwise move and
act on its own, without the need for constant supervision. To this end, the
robot will have ground-breaking perception and modelling capabilities to
represent the current social situation (the focus of WP2), coupled with an
innovative cognitive architecture designed to combine internal social drives
with domain-specific action policies learnt from the end-users (WP4). The robot
actions themselves are designed to be limited to non-verbal communication
mechanisms: non-verbal utterances using sounds, gaze, joint attention,
expressive motions. In WP3, my team will work with a choreographer and a sound
expert to create a new grammar of expressive motions, combined with a novel
modality based on \emph{soundscapes}: sound landscapes that the robot can
modulate to influence the mood of the social environment (calm, excited,
worried, etc.).

As a ground-breaking project, \project will assert and reinforce the European leadership in AI and
intelligent robotics, in line with the EU's strong societal values: by developing
socially responsible AI that guarantees, by design, long-term benefits to the
society. The very first task T1.1, spread over the first 4 years of the project,
specifically addresses and frames the ethical underpinnings of social robots,
and delivers the guidelines that we need to inform our future policies on social
robotics. Combined with beyond-state-of-the-art technological developments,
\textbf{the \project research programme will provide a major contribution in
securing a safe and responsible digital future in Europe}. 

Finally, \project is also about asserting and reinforcing the European
leadership in AI and intelligent robotics, in line with EU strong societal
values: a socially responsible AI, that guarantees, by design, long-term
benefits to the society. This requires leading major technological advances;
leading the development of the conceptual framework around socially intelligent
robots that we need to inform future policy making; but also \textbf{a strong
leadership to meaningfully involve the public at large in the design of these
technologies}. Through its objectives and methodology, \textbf{\project will
have a major contribution to building this capacity in Europe}. 




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Work programme outlook}


%\vspace{0.5em}
%\begin{itemize}
%
%    \item What are the conceptual, algorithmic and technical prerequisites to
%        design and implement such an autonomous \& responsible robots? in
%        particular, what social context understanding and (machine) learning
%        architectures are required to \textbf{enable long-term autonomy} and,
%        eventually, \textbf{engagement} between a robot and its end-users?
%
%    \item What are the conditions and methodologies enabling large scale data
%        acquisition of \textbf{real world, user-driven robots behaviours}? How
%        to then train robots to become \textbf{progressively autonomous}?  And
%        ultimately, how to balance \textbf{autonomy} of the robot with the
%        necessary \textbf{behaviour transparency} and \textbf{human oversight}?
%
%    \item What are the public expectations with respect to the role of social
%        robots, and how can we \textbf{collaboratively design}
%        \textbf{autonomous}, yet \textbf{responsible, beneficial, socially
%        acceptable robots}?
%
%\end{itemize}
%
%\vspace{0.5em}
%\noindent From these questions, I derive the following four objectives that are
%the guiding principles of my research program, both in the short term, and at a
%10-15 years horizon:


%\subsection{Work plan outlook}
%
%My research program could begin rapidly, using publicly available resources,
%including machine learning architectures like Transformers, combined with open-source
%pre-trained Large Language Model backbones; and state-of-art HRI tools like
%ROS4HRI~\autocite{mohamed2021ros4hri} to represent in real-time the social
%environment of the robot. While long and complex data collection campaigns would
%have to be organised, and training infrastructure would need to
%be designed, I expect initial results in the first 3 to 5 years.
%
%This is also a long-term vision: on the one hand, the rapid pace of progress
%of technology (novel deep machine learning architectures, novel HRI tools for
%human and scene understanding) continuously opens novel investigation
%venues; one the other hand, the success of my research vision hinges on
%real-world, long-term experimental work: deploying robots in the healthcare
%sector, creating the conditions for adoption by the end-users, running
%long-term deployments with the end-users are long terms aims
%,... these research activities will take
%place over long period of time.

%\subsection{Importance and impact}
%
%My research program has the potential to be groundbreaking: until now,
%autonomous social robots have had little real world success. Experiments and
%deployments have been mostly limited to constrained application domains, where
%rigid action policies (scripts, task planners) could be sufficient. State-of-art
%robots however fail to handle the complexity and unpredictability of real world
%environments (like the ones encountered in the healthcare domain). In addition,
%these systems see poor field adoption due to several factors including
%difficulty of use, wrong expectations, perceived complexity.
%
%This research program is also important: as socially assistive robots quickly
%develop, it is critical to equip ourselves with a deeper understanding and
%intellectual framing of what social robots \emph{could} and \emph{should} be,
%paving the way for their much broader adoption in the coming years: I will
%actively contribute to this aim, by leading the design and implementation of
%socially-intelligent robots that are socially useful, acceptable in the
%long-term, and ethically responsible, but also by furthering my engagement to
%interdisciplinary work, and broad engagement with the society and policy makers.







%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%How this general
%principle translates into specific guidelines and algorithms -- while taking into
%account the principles of a responsible AI -- is the central
%contribution of Work Package 1.

% This socially-driven goal forms what we call a \emph{social
%teleology}. its own goals have this objective can only be achieved if the
%robot is \textbf{socially-driven}: the robot's behaviours must be driven by the
%intention to support positive human-human interactions. 


I frame these hypotheses with the idea of \textbf{robot-supported human-human
interactions}, a novel conceptual framework to `think' the future human-robot
interactions. I will co-construct this framework through large scale public
engagement: for a whole year, I will deploy the \project robot within the City
Lab of Bristol's science centre \emph{WeTheCurious}, relinquishing the control
of the robot to the visitors themselves. Tasked with remotely operating the
robot to assist fellow visitors, I will accompany them in `inventing by doing' a
new grammar of social interactions: what does it mean for a robot to help? How
to do so in the dynamic, messy, environment of a science centre? What are acceptable
behaviours? Can we see new social norms emerge? At the end of this experiment,
we expect 1000s of people to have had experienced -- and co-designed -- how
robots should interact with humans in a positive, helpful way, and each of these
experiences will contribute to uncovering and designing the basic principles of
social interaction for robots. This work is the focus of WP1.

While most of the interactions in the science centre will be short-lived, two further
large scale experiments will take place over the course of the project: a
one-year experiment in one of Bristol's Special Education Needs (SEN) school,
helping 250+ children with psycho-social impairments to develop their social
skills; a second one-year experiment at the Bristol's children hospital, where
the robot will join one of the wards where 30+ children with long-term conditions
stay for months, and engage with the children into playful social activities: telling
stories, triggering group activities with other children, providing additional
social presence. In both these experiments, the robot behaviours will be
co-designed with, and learnt from the end-users themselves: nurses, teachers,
parents, and where possible, the children themselves.


\section{Overview of the \project work programme}

Socially intelligent robots require unique, beyond state-of-the-art,
capabilities to \emph{(1)} understand the social interactions (social
situation awareness), \emph{(2)} autonomously decide the best course of action for
short-term and longer-term social influence, and \emph{(3)} perform the
appropriate social actions and exert said influence in an appropriate,
responsible manner.

Not only the required technology is itself beyond state-of-the-art (and will be
researched and integrated in WP2, WP3 and WP4), but the
interplay between technology, socio-cognitive psychology, privacy and ethics is
only starting to be researched and understood. \project offers an
strong vision and an ambitious, evidenced-based, methodology to significantly
advance our understanding of this multi-faceted problem.


\begin{itemize}
    \item \textbf{O1: conceptual framing} To construct a solid conceptual
        framing around the multidisciplinary question of responsible human-robot
        interactions, answering questions like: What should motivate the robot
        to step in and attempt to help? or: What social norms are applicable to
        the robot behaviours? Building on the extensive body of work on
        Responsible AI, I will investigate the basic principles of
        responsible robot-mediated social interactions, that must form the
        foundations of a socially useful robot, accepted and used in the long
        run.  Using user-centred design and participatory design methodologies,
        I will identify the determinants and parameters of a responsible social
        intervention, performed by a socially-driven robot, and formalise them
        in practical principles.

    \item \textbf{O2: physical-social representation and reasoning} To
        effectively and responsibly interact with its environment, the robot
        must first build a comprehensive and continuously updated model, from its
        spatial and physical configuration, to its social dynamics. I will
        design and develop a novel cognitive capability of artificial
        \emph{social situation assessment} to enable the robot to represent
        real-time social dynamics in its environment. I will achieve this
        breakthrough by combining existing model-based approaches \TODO{refs}
        (including my recent research on social state modeling \TODO{refs}, with
        the expressive power of the new \emph{social embeddings} that I have
        recently introduced.

    \item {\bf O3: goal-driven, responsible decision making} I aim to create
        robot behaviours that are perceived as purposeful and intentional
        (long-term goals), while being shaped by a user-created and
        user-controlled action policy.  I will integrate long-term social goals,
        arising from the interaction principles of \textbf{O1}, with the social
        modeling capability of \textbf{O2}, into a principled, goal-driven
        cognitive architecture, with responsible AI guarantees. The breakthrough
        will come from combining these long-term social goals with bottom-up
        action policies, designed and learnt from the end-users using
        human-in-the-loop attention-based machine learning.

        I want to specifically test the following two hypotheses: first, that
        long-term social goals, if suitably co-designed with the public and
        stakeholders and properly integrated into the robot as a \emph{social
        teleology}, will create the perception that the robot is intentional and
        purposeful. This will in turn elicit sustained engagement from its human
        users.

        Second, that human-in-the-loop machine learning can be used to ensure an
        additional layer of human oversight and a level of behavioural
        transparency.  Human-in-the-loop reinforcement learning -- as
        implemented in the SPARC approach that I have developed with my students
        and already used in complex social
        environments~\parencite{senft2017supervised,senft2019teaching,winkle2020insitu}
        -- relies on an end-user `teacher'. This teacher initially fully
        controls the robot (via teleoperation) while it learns the action
        policy, and then progressively relinquishes control up to a point where
        the robot is effectively autonomous. As I previsouly argued
        in~\textcite{senft2019teaching}, this approach leads to increased
        control and ownership of the system, and as a result, increased trust
        from the end-users.


    \item{\bf O4: ambitious field research} Finally, the last major objective of
        my research project is to demonstrate the effectiveness of my approach
        in complex, real-world conditions. This means deploying the socially
        interactive robots in existing social \emph{ecosystems} that are
        sufficiently complex and open to explore novel social interactions. My
        objective is also to show that this real-world deployment can be
        successfully driven by the `end-to-end' involvement of all the end-users
        and stakeholders: from defining the robot's role, from the different
        perspective of each end-user, to actually designing and `teaching' the
        robot what to do.


\end{itemize}


These objectives are investigated across five work-packages.

\subsection{WP1: \textbf{\wpOne}}

WP1 aims at establishing the conceptual and ethical framework around the idea of
\emph{robot-supported human-human interactions}. It does so by co-creating
patterns of interaction and norms with the general public, using a unique
combination of ethnographic observations and `crowd-sourced' interaction
patterns.

\begin{framed}
    \textbf{Main outcomes:} A theoretical framework to `think' the role of
    social robots and guidelines to inform policy making (including ethical
    implications); a set of operational \& co-created interaction principles; a
    large dataset of social human-robot interactions

    \textbf{Timeframe:} \textbf{Y1-Y3}; one senior post-doc (PD1)
with background in sociology of technology.
\end{framed}


\textbf{T1.1 -- Conceptual framing and ethics of robot-supported social
interactions}


The first task in WP1 is to research and define the conceptual framework around
questions like: what role should social robots have? Where
to set the boundaries of artificial social interactions? What does
`ethical-by-design', `responsible-by-design' mean in the context of social
human-robot interactions? 

Each of the field experiments (T1.2, T5.1. T5.2) will both \emph{build on} and
\emph{feed into} the framework developed in this task. In addition, four
two-days workshops with the \project Ethics Advisory Board, spread over the
duration of the project, will act as ethical milestones.

\textbf{T1.2 -- Crowd-sourced patterns of robot-supported social
interactions} The conceptual framework identified in T1.1 is translated
into a set of \emph{interaction design principles} and \emph{determinants} that
will together form a set of requirements and objectives for the socio-cognitive
capabilities and architecture developed in WP2 and WP4.

In order to anchor T1.2 into the reality and complexity of human social
interactions, and to involve the society at large into the design of these
patterns and norms, I will embed one \project robot in the Bristol Science
Centre WeTheCurious for a whole year (Y2). With the help of a researcher, the
visitors will be guided into tele-operating the robot to assist other visitors,
and, by doing so, co-design what a good robot helper should be. This will
generate the quantitative and qualitative data to inform questions like `what
role for the robot?', `when to intervene?', `what are the effective and
acceptable social influence techniques?'. It will also be a unique example of
crowd-sourcing at a large scale, with the general public, the interaction design
of social robots.  The generated dataset will also be used as data source in WP2
and WP3.

\textbf{Specific resources} The Bristol's Science Centre is fully committed to the
project, will include \project in its official programme of activities, and will
provide in-kind training for the \project researcher based at the centre.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% WeTheCurious
% 
% - one robot completelty controlled by children, one by adults
% 
% what to learn?
% 
% - when to approach? when to prompt? [example of the salesman/museum facilitator]
% - when is the right time to help/intervene or not? 'child being told off by
% parents -> not the right time!'
% - group interactions -> when to intervene? what about peer-pressure? eg what if
% I tell off one child in front of another?
% - break the barrier for participation. Japanese Journal paper -> facilitating students questions
% - impact on moral norms? what behaviours is acceptable?
% - what role for the robot? another mediator? a peer?
% - what can we do with that 'alien creature'
% 
% - robot taking one child to talk to the museum mediators ("I, robot, am  shy!
% would you come with me?")
% 
% - learning how to adjust behaviour based on personality
% - 'why do I behave like that with that person, and like this with that other
% person?'
% 
% - reinforcement learning instead of human-in-the-loop -> what reinforcement
% signal? engagement
% 
% - the robot that 'take sides': take side against the adults? -> bending in its
% role?
% 
% 
% - social embarassment
% - space for pretence: the robot can adopt an 'artificial role' as long as it is
% possible (accpetable/...) to pretend the robot is



\subsection{WP2: \textbf{\wpTwo}}


In WP2, the project addresses the key scientific and technical pre-requisites to
effectively deliver WP4's cognitive architecture; namely the perception and modeling of
the spatio-temporal and social environment of the robot. This includes spatial
characteristics (proxemics; group dynamics; complex, dynamic attentional
mechanisms); psycho-social determinants (social roles and hierarchies; social
groups; mental modelling; anthropomorphic ascriptions); temporal characteristics
(effects of novelty; dynamics of anthropomorphism and mental ascriptions; group
dynamics). I have investigated many of these socio-cognitive capabilities in
isolation (Table~\ref{pi-expertise}), and this WP is about
\emph{integrating} them into a coherent perceptual subsystem, significantly
extending the state-of-the-art~\cite{lemaignan2017artificial, baxter2016cognitive}.

\begin{framed}
    \textbf{Main outcomes:} A complete pipeline for spatio-temporal and social
    situation assessment, build as open-source ROS nodes, and able to map in
    real time the physical and social environment of the robot.

    \textbf{Timeframe:} \textbf{Y1-Y4}; one post-doc (PD2) in social
signal processing/machine learning/cognitive modelling.
\end{framed}

\textbf{T2.1 -- Hybrid situation assessment and knowledge representation} This
task builds the foundational spatio-temporal and symbolic perception and
representation system for the robot. It will integrate the state-of-the-art in
spatio-temporal situation assessment that I have previously
developed~\cite{lemaignan2018underworlds, sallami2019simulation} with recent
advances in data-driven semantic labelling (for instance, using 4D convolution
nets like MinkowskiNet~\cite{choy20194d}), and a symbolic knowledge base (like
my own ontology-based one~\cite{lemaignan2010oro}) in order to create a coherent
system of representations for the cognitive architecture of the robot.

\textbf{T2.2 -- Multi-modal human model} This task focuses on the processing and
modelling of social signals, extending existing techniques, both model-based
(eg~\cite{gunes2017automatic,lemaignan2016realtime}) and data-driven based
(eg~\cite{bartlett2019what}). This task goes beyond the state-of-the-art by
looking specifically at resolving highly dynamical signals (like gaze saccades
and micro facial expressions). Required datasets will be drawn from my previous
work~\cite{lemaignan2018pinsoro}, as well as from the project experiments (T1.2,
T5.1, T5.2).

\textbf{T2.3 -- Interaction and group dynamics} Building on T2.2, T2.3
investigates the automatic understanding and modelling of group-level social
interactions~\cite{tapus2019perceiving}, including
$f$-formations~\cite{marshall2011using}, sociograms (as done
in~\cite{garcia2016hybrid} for instance), and inter-personal
affordances~\cite{pandey2013affordance}. This task builds on literature on 
social dynamics analysis (eg~\cite{durantin2017social,jermann2009physical,
martinez2019collocated}) to apply it to real-time social assessment by a robot,
itself embedded into the interaction.

\textbf{T2.4 -- Integrated model of the social environment} The integration of
the social cues from T2.2 and T2.3 results in a socio-cognitive model of the
social environment of the robot, that effectively extends the representation
capabilities of T2.1 to the social sphere. The result of T2.4 is an AI module
that implements a full social assessment pipeline, from social signal perception
to higher-level socio-cognitive constructs. T2.4 also includes a
focused experimental programme (based on the protocols designed by Frith and
Happé~\cite{frith1994autism}, that I introduce in~\cite{lemaignan2015mutual}) to
demonstrate in isolation the resulting socio-cognitive capabilities.


\subsection{WP3: \textbf{\wpThree}} 

Mirroring WP2's focus on understanding the social interactions, WP3 addresses the
question of social behaviour \emph{production}: how to create natural,
non-repetitive behaviours, engaging over a sustained period of time. The robot
behaviours will be exclusively non-verbal (non-verbal utterances, gaze, joint
attention, facial expressions and expressive motions), and will include
soundscapes as a novel non-verbal interaction modality.

\begin{framed}

    \textbf{Main outcomes:} A new method to automatically design complex and
    non-repetitive social behaviours, with a focus on non-verbal communication;
    research on soundscapes as a novel non-verbal modality for human-robot
    interaction.

    \textbf{Timeframe:} \textbf{Y2-Y5}; one post-doc (PD3) in machine learning/learning from
demonstration.

\end{framed}

\textbf{T3.1 -- Behavioural baseline} T3.1 establishes a baseline for behaviour
generation, by surveying and implementing the current state of the art
(behaviours library, activity switching~\cite{coninx2016towards}). This
baseline will enable early in-situ experimental deployments, while also
providing a comparison point for T3.2.

\textbf{T3.2 -- Generative neural network for social behaviour production}
\project aims at significantly advancing the state of the art in this regard, by
combining two recent techniques: (1) generative neural networks for affective
robot motion generation~\cite{marmpena2019generating,suguitan2020moveae} (with
training data created with an expert choreographer); (2) interactive machine
learning in high-dimensional input/output spaces, where I have shown with my
students promising results for generating complex social
behaviours~\cite{senft2019teaching, winkle2020couch} that fully involve the
end-users~\cite{winkle2018social}. Modulating (1) with the learnt features of
(2), I target a breakthrough in robots' social behaviours generation: the
generation of non-repetitive, socially congruent and transparent social
behaviours (including gestures but also gazing behaviours and facial
expressions).

\textbf{T3.3 -- Non-verbal behaviours and robot soundscape} In task T3.3, we
introduce a novel non-verbal interaction modality for robots, based on
soundscapes: soundscapes are about creating a sound environment that reflects a
particular situation; they also have been shown to be an effective intervention
technique in the context special needs
interventions~\cite{greher2010soundscape}. The soundscapes that I will create
are `owned' by the robot, that can manipulate ithem itself, eg to create an
approachable, non-threatening, non-judgmental, social interaction context, or to
the establish the interaction into a trusted physical and emotional safe-space
for the user.

\textbf{Specific resource}: these soundscapes will be co-designed with Dr.
Dave Meckin, an expert on sound design for vulnerable children, who also works
at the host institution.

\subsection{WP4: \textbf{\wpFour}}

In WP4, I will design a novel socio-cognitive architecture for the social
robots, and implement it on the IIT R1 robot.  WP4 will integrate together the
modeling capabilities and behaviour production developed in WP2 and WP3, with a
dual action policy: a policy driven by a social teleology (eg an artificial
intrinsic motivation to act socially), and a policy learned through
human-in-the-loop machine learning. This WP is high-risk/high-gain: while sustaining
long-term engagement in a principled way remains one of major scientific
challenge in social robotics~\cite{hoffman2019anki}, the WP suggests a very novel
approach to goal-driven socio-cognitive architectures, with the potential of
unlocking long-term social engagement by endowing the robot with its own
intentionality~\cite{wiese2017robots}, while maintaining human oversight.

\begin{oframed}
    \textbf{Main outcomes:} An integrated cognitive architecture for social
    robots, driven by both long-term social goals, and machine-learnt action
    policies; a reference open-source implementation, enabling long-term
    autonomy on the IIT R1 robot.

    \textbf{Timeframe:} \textbf{Y1-Y5}; one post-doc (PD4) in cognitive
    robotics; one PhD student (PHD1).

\end{oframed}

\textbf{T4.1 -- A social teleology for robots} The idea of a \emph{teleological}
(ie goal-driven) robot architecture for social interaction is very novel
(existing literature on teleological robots only focuses on simple cognitive
systems~\cite{oudeyer2005playground,forestier2017unified}). This task designs
and implements such an architecture on the R1 robot. It first identifies from
the interaction patterns and determinants uncovered in T1.2 \emph{interaction
principles}, that are then mapped into \emph{long-term interaction goals}, capable of
driving the robot actions over a period of time.

\textbf{T4.2 -- Learning from humans to achieve `by-design' responsible \&
trustworthy AI} Building on my recent results on human-in-the-loop social
learning~\cite{senft2017supervised,senft2019teaching,winkle2020couch}, this task
implements the mechanics to allow human end-users to progressively teach the
robot a domain-specific social policy.  This task also qualitatively researches
how human-in-the-loop machine learning enables a more trustworthy AI system, by
involving the end-users in the creation of the robot behaviours, resulting in
explainable behaviours for the end-users.

\textbf{T4.3 -- Integrating a socially-driven architecture for long-term
interaction} Building on my previous work on cognitive
architecture~\cite{lemaignan2017artificial}, this task brings together, in a
principled manner, the perceptual (WP2) and behavioural
(WP3) capabilities of the robot, as well as the social policies created in T4.1 and
T4.2. T4.3 will specifically look at long term autonomy, including long-term
social goals, cognitive redundancy, and behavioural complexity.

T4.3 will also develop the arbitration mechanism that combines the robot's
social teleology (T4.1) with the human-taught action policy (T4.2). This
arbitration mechanism will build on research on reinforcement learning for
experience transfer~\cite{madden2004transfer} that enables the re-assessment of
a policy (here, our intrinsic motivation) based on previous experience (here,
the human-taught policy).

\subsection{WP5: \textbf{\wpFive}}

Finally, WP5 aims at convincingly demonstrating the importance and positive
impact that socially-driven, socially-responsible robotics may have. The
experimental work of \project will be organised around two ambitious long-term
studies, in complex, real-world environments: a network of special educative
needs (SEN) schools, and the Bristol Children's Hospital.

These environments also put the project in the unique position of actually
delivering high societal impact: I anticipate 30+ hospitalised children, and 250
SEN-educated children to directly benefit from the project, exploring how robots
can have a net social utility, while being accepted as effetive tools by field
practitioners. Both these deployments will take place within the strict ethical
framework established in T1.1.

\begin{oframed}

    \textbf{Main outcomes:} Two long-term deployments of a social robot in
    real-world, high impact environments demonstrating long-term acceptance and
    social utility; large (anonymous) datasets of complex, real-world
    human-robot interactions.

    \textbf{Timeframe:} \textbf{Y3-Y5}; one post-doc (PD4, shared with WP4).

\end{oframed}

\textbf{T5.1 -- A robot companion to support physical, mental and social
well-being in SEN schools} This task aims at demonstrating robot-supported
social interventions within Bristol's network of SEN schools.  During a one-year
period (Y3), the robot will be based in schools, with interventions co-designed
with the teachers, the parents and the students, both through preliminary
focus groups and in-situ machine learning.

The envisioned interventions include: initiating group games; enquiring students
about their well-being; co-teaching material with teachers; fostering
interaction situations between the children.

\textbf{Specific resources:} The task will be supported by local SEN researcher
Dr. Nigel Newbutt, who has a long track record and on-going research
partnerships with Bristol's special needs schools.


\textbf{T5.2 -- A robot companion to support isolated children during their
hospital stay} Over the course of this second, one-year long (Y4)
experiment, my team will deploy one \project robot in the long-term condition
paediatric ward at the Bristol Children's Hospital.  Using a \emph{mutual shaping}
approach~\cite{winkle2018social} to design the role of the robot with the
different stakeholders (nurses, doctors, parents, children), I will
experimentally investigate how a social robot can support hospitalised children
with long-term conditions. The robot's role will revolve around facilitating
social interactions between possibly socially isolated children, by fostering
playful interaction amongst children, within the ward.

\textbf{Specific resources:} Several preparatory meetings already took place
with the head of the hospital education service J. Bowyer, who will support the
project, granting access to the long-term conditions ward, and sponsoring the
project through the hospital-specific ethics process.


\section{Capacity of the Principal Investigator to deliver on the work programme}

While the project is ambitious, I am in a unique position to deliver on the
\project work plan. I already have established international recognition in
human-robot interaction and have likewise demonstrated strong leadership by
leading research teams in three different institutions (see Sections B1.b and
B1.c below). Importantly, as illustrated in Table~\ref{pi-expertise}, the
breadth of my interdisciplinary research covers the scientific expertise
required by the project, providing me with a unique overall perspective and
understanding of the domain. I am also a technology expert, with major software
and hardware contributions to the robotic community (see Section B1.c). As such,
I have a excellent grasp of the technical feasibility of the proposed work.


\begin{table}[h]
    \centering
    \caption{\small PI's domains of expertise relevant to the \project project}
    \begin{tabular}{rp{0.6\linewidth}}
        \toprule
        %\bf Expertise domain                  & \bf Corresponding publications by PI          \\
        %\midrule
        \textbf{Psycho-social underpinnings of HRI} \\  
        human factors & \small anthropomorphism~\cite{lemaignan2014dynamics}, cognitive
        correlates~\cite{lemaignan2014cognitive}, social influence~\cite{winkle2019effective} \\
        trust, engagement, social presence & \small \cite{flook2019impact,lemaignan2015youre,fink2014which,irfan2018social} \\
        theory of mind & \small perspective taking~\cite{ros2010which, warnier2012when}, social mutual modelling~\cite{lemaignan2015mutual,dillenbourg2016symmetry} \\
        \midrule
        \textbf{Social signal processing}\\
        non-verbal behaviours & \small
        attention~\cite{lemaignan2016realtime,mohamed2022automatic},
        child-child dataset~\cite{lemaignan2018pinsoro}\\
        internal state decoding~\cite{bartlett2019what, webb2022measuring} \\
        verbal interactions & \small speech recognition~\cite{kennedy2017child}, dialogue grounding~\cite{lemaignan2011grounding} \\
        \midrule
        \textbf{Behaviour generation} \\
        social behaviours & \small \cite{lallee2011towards}, verbal interactions~\cite{wallbridge2019generating, wallbridge2019towards}, physical interactions~\cite{gharbi2013natural} \\

        \midrule
        \textbf{Socio-cognitive architectures} \\
        technical underpinnings & \small \cite{mallet2010genom3,lemaignan2015pyrobots,mohamed2021ros4hri} \\
        architecture design & \small \cite{lemaignan2017artificial, baxter2016cognitive,lemaignan2014challenges,lallee2012towards, mallet2010genom3} \\
        knowledge representation & \small
        ontologies~\cite{lemaignan2010oro, lemaignan2013explicit} \\    
        spatio-temporal modelling & \small object
        detection~\cite{wallbridge2017qualitative}, physics-aware situation
        assessment~\cite{lemaignan2018underworlds,sallami2019simulation} \\
        \midrule
        \textbf{Fieldwork in HRI} & \small in
        classrooms~\cite{hood2015when, lemaignan2016learning, jacq2016building,
        baxter2015wider,kennedy2016cautious,senft2018robots,lemaignan2022social},
        at home~\cite{mondada2015ranger}, in public
        spaces~\cite{alhafnawi2022deliberative}\\
        %\midrule
        %Robot hardware design for interaction & \small \cite{ozgur2017cellulo, hostettler2016realtime} \\
        \midrule
        \textbf{Human-centered robotics} \\
        participatory design & \small \cite{winkle2018social}\\
        interactive reinforcement learning & \small \cite{senft2017leveraging,senft2017supervised, senft2019teaching,winkle2020couch, winkle2020insitu,winkle2021leador} \\        
        \midrule
        \textbf{Dataset acquisition} & \small \cite{kennedy2017child,lemaignan2018pinsoro,sallami2020unexpected,webb2023sogrin} \\
        \midrule
        \textbf{Responsible robotics} & \small \cite{lemaignan2021unicef} \\
        \midrule
        \textbf{Healthcare \& Assisstive robotics} & \small
        \cite{winkle2018social,cooper2023challenges} \\
        \bottomrule
    \end{tabular}
    \label{pi-expertise}
\end{table}

The project is ambitious, with an experimental programme that goes significantly
beyond the state of the art. It will provide a lasting scientific and
technical legacy, that extends well beyond the end of the fellowship. As a
high-risk/high-gain project, \project will also be a powerful enabler: by the
end of the fellowship, I will have established myself as a world-leader in the
emerging field of socially-driven, responsible autonomous robots, significantly
reinforcing the European capacity in this critical field for our digital future.



\newpage

\printbibliography



